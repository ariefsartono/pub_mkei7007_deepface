{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main_model_awal.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1PWetxYwFD4iGkym2eiNOnxQs-ARLgyV-","authorship_tag":"ABX9TyOcRC4HA9Kawz7db9xxMY85"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Step 1 - Download and extract files:\n","- facenet_keras.h5\n","- datakelas.zip"],"metadata":{"id":"Jkk5J-FOqB47"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nm58REyapm-8","executionInfo":{"status":"ok","timestamp":1652717906564,"user_tz":-420,"elapsed":11845,"user":{"displayName":"33221018 Arief Sartono","userId":"11452593645263556956"}},"outputId":"1f1cdaac-469c-497c-834b-52af30eddb0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1kv4Q5T0dNjWSVWcV6_IU9zXq4-5eszh9\n","To: /content/facenet_keras.h5\n","100% 92.4M/92.4M [00:00<00:00, 99.0MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1jt1BltL_8PSDLtT00VwkO57YsR23IE9b\n","To: /content/datakelas.zip\n","100% 140M/140M [00:01<00:00, 81.4MB/s]\n","Done\n"]}],"source":["!gdown --id 1kv4Q5T0dNjWSVWcV6_IU9zXq4-5eszh9\n","!gdown --id 1jt1BltL_8PSDLtT00VwkO57YsR23IE9b\n","from zipfile import ZipFile\n","file_name = \"/content/datakelas.zip\"\n","#file_name = \"datakelas.zip\"\n","\n","with ZipFile(file_name, 'r') as zip:\n","  zip.extractall()\n","  print('Done')"]},{"cell_type":"markdown","source":["Step 2 - Mount Google Drive (bila belum di-mount)"],"metadata":{"id":"aMsBlRhUr035"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OC3Z7KYyp9Mj","executionInfo":{"status":"ok","timestamp":1652718213110,"user_tz":-420,"elapsed":12809,"user":{"displayName":"33221018 Arief Sartono","userId":"11452593645263556956"}},"outputId":"8b8323d7-db95-43d2-b45a-39fbf21cdb0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Step 3 - Extract the faces from photographs in datakelas.zip"],"metadata":{"id":"iIgalgFrrxpO"}},{"cell_type":"code","source":["!pip install mtcnn\n","#%xmode Verbose\n","\n","from os import listdir\n","from os.path import isdir\n","from PIL import Image\n","from matplotlib import pyplot\n","from numpy import savez_compressed\n","from numpy import asarray\n","from mtcnn.mtcnn import MTCNN\n","\n","# extract a single face from a given photograph\n","def extract_face(filename, required_size=(160, 160)):\n","\t# load image from file\n","\timage = Image.open(filename)\n","\t# convert to RGB, if needed\n","\timage = image.convert('RGB')\n","\t# convert to array\n","\tpixels = asarray(image)\n","\t# create the detector, using default weights\n","\tdetector = MTCNN()\n","\t# detect faces in the image\n","\tresults = detector.detect_faces(pixels)\n","\t# extract the bounding box from the first face\n","\tx1, y1, width, height = results[0]['box']\n","\t# bug fix\n","\tx1, y1 = abs(x1), abs(y1)\n","\tx2, y2 = x1 + width, y1 + height\n","\t# extract the face\n","\tface = pixels[y1:y2, x1:x2]\n","\t# resize pixels to the model size\n","\timage = Image.fromarray(face)\n","\timage = image.resize(required_size)\n","\tface_array = asarray(image)\n","\treturn face_array\n","\n","# load images and extract faces for all images in a directory\n","def load_faces(directory):\n","\tfaces = list()\n","\t# enumerate files\n","\tfor filename in listdir(directory):\n","\t\t# path\n","\t\tpath = directory + filename\n","\t\t# get face\n","\t\tface = extract_face(path)\n","\t\t# store\n","\t\tfaces.append(face)\n","\treturn faces\n","\n","# load a dataset that contains one subdir for each class that in turn contains images\n","def load_dataset(directory):\n","\tX, y = list(), list()\n","\t# enumerate folders, on per class\n","\tfor subdir in listdir(directory):\n","\t\t# path\n","\t\tpath = directory + subdir + '/'\n","\t\t# skip any files that might be in the dir\n","\t\tif not isdir(path):\n","\t\t\tcontinue\n","\t\t# load all faces in the subdirectory\n","\t\tfaces = load_faces(path)\n","\t\t# create labels\n","\t\tlabels = [subdir for _ in range(len(faces))]\n","\t\t# summarize progress\n","\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n","\t\t# store\n","\t\tX.extend(faces)\n","\t\ty.extend(labels)\n","\treturn asarray(X), asarray(y)\n","\n","# load train dataset\n","trainX, trainy = load_dataset('/content/datakelas/train/')\n","print(trainX.shape, trainy.shape)\n","# load test dataset\n","testX, testy = load_dataset('/content/datakelas/val/')\n","# save arrays to one file in compressed format\n","savez_compressed('kelas-dataset.npz', trainX, trainy, testX, testy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqbiVF6drs3u","executionInfo":{"status":"ok","timestamp":1652718675527,"user_tz":-420,"elapsed":265394,"user":{"displayName":"33221018 Arief Sartono","userId":"11452593645263556956"}},"outputId":"0ac1410e-de28-42f8-c3ad-98d26f906871"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mtcnn\n","  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.8.0)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.21.6)\n","Installing collected packages: mtcnn\n","Successfully installed mtcnn-0.1.1\n","WARNING:tensorflow:5 out of the last 206 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f837f034f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f837ee5db90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",">loaded 3 examples for class: mina_ismu_rahayu\n",">loaded 1 examples for class: kemas_muhammad_irsan_riza\n",">loaded 2 examples for class: meza_silvana\n",">loaded 3 examples for class: m_khaerul_naim\n",">loaded 1 examples for class: meredita_susanty\n",">loaded 2 examples for class: yaya_setiadi\n",">loaded 1 examples for class: leni_fitriani\n",">loaded 7 examples for class: baud_prananto\n",">loaded 1 examples for class: arief_ichwani\n",">loaded 1 examples for class: reza_budiawan\n",">loaded 10 examples for class: unknown\n",">loaded 16 examples for class: arief_sartono\n",">loaded 2 examples for class: riyanto\n",">loaded 4 examples for class: adiyasa_nurfalah\n",">loaded 2 examples for class: lathifah_arief\n",">loaded 1 examples for class: sulthoni_ashiddiiqi\n",">loaded 2 examples for class: imam_ekowicaksono\n",">loaded 2 examples for class: ahmad_luky_ramdani\n",">loaded 1 examples for class: mohamad_idris\n",">loaded 1 examples for class: ricky_isfandiari\n",">loaded 1 examples for class: yulrio_brianorman\n",">loaded 1 examples for class: hartanto_tantriawan\n",">loaded 1 examples for class: dewi_tresnawati\n",">loaded 5 examples for class: rahman_indra_kesuma\n",">loaded 4 examples for class: handoko_supeno\n",">loaded 3 examples for class: varuliantor_dear\n",">loaded 1 examples for class: achmad_indra_aulia\n","(79, 160, 160, 3) (79,)\n",">loaded 1 examples for class: mina_ismu_rahayu\n",">loaded 1 examples for class: kemas_muhammad_irsan_riza\n",">loaded 1 examples for class: meza_silvana\n",">loaded 1 examples for class: m_khaerul_naim\n",">loaded 1 examples for class: meredita_susanty\n",">loaded 1 examples for class: yaya_setiadi\n",">loaded 1 examples for class: leni_fitriani\n",">loaded 1 examples for class: baud_prananto\n",">loaded 1 examples for class: arief_ichwani\n",">loaded 1 examples for class: reza_budiawan\n",">loaded 1 examples for class: unknown\n",">loaded 1 examples for class: arief_sartono\n",">loaded 1 examples for class: riyanto\n",">loaded 1 examples for class: adiyasa_nurfalah\n",">loaded 1 examples for class: lathifah_arief\n",">loaded 1 examples for class: sulthoni_ashiddiiqi\n",">loaded 1 examples for class: imam_ekowicaksono\n",">loaded 1 examples for class: ahmad_luky_ramdani\n",">loaded 1 examples for class: mohamad_idris\n",">loaded 1 examples for class: ricky_isfandiari\n",">loaded 1 examples for class: yulrio_brianorman\n",">loaded 1 examples for class: hartanto_tantriawan\n",">loaded 1 examples for class: dewi_tresnawati\n",">loaded 1 examples for class: rahman_indra_kesuma\n",">loaded 1 examples for class: handoko_supeno\n",">loaded 1 examples for class: varuliantor_dear\n",">loaded 1 examples for class: achmad_indra_aulia\n"]}]},{"cell_type":"markdown","source":["Step 4 - Calculate Face Embedding"],"metadata":{"id":"8VY5MXWgsp8U"}},{"cell_type":"code","source":["# calculate a face embedding for each face in the dataset using facenet\n","from numpy import load\n","from numpy import expand_dims\n","from numpy import asarray\n","from numpy import savez_compressed\n","from keras.models import load_model\n","\n","# get the face embedding for one face\n","def get_embedding(model, face_pixels):\n","\t# scale pixel values\n","\tface_pixels = face_pixels.astype('float32')\n","\t# standardize pixel values across channels (global)\n","\tmean, std = face_pixels.mean(), face_pixels.std()\n","\tface_pixels = (face_pixels - mean) / std\n","\t# transform face into one sample\n","\tsamples = expand_dims(face_pixels, axis=0)\n","\t# make prediction to get embedding\n","\tyhat = model.predict(samples)\n","\treturn yhat[0]\n","\n","# load the face dataset\n","data = load('kelas-dataset.npz')\n","trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n","print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n","# load the facenet model\n","model = load_model('facenet_keras.h5')\n","print('Loaded Model')\n","# convert each face in the train set to an embedding\n","newTrainX = list()\n","for face_pixels in trainX:\n","\tembedding = get_embedding(model, face_pixels)\n","\tnewTrainX.append(embedding)\n","newTrainX = asarray(newTrainX)\n","print(newTrainX.shape)\n","# convert each face in the test set to an embedding\n","newTestX = list()\n","for face_pixels in testX:\n","\tembedding = get_embedding(model, face_pixels)\n","\tnewTestX.append(embedding)\n","newTestX = asarray(newTestX)\n","print(newTestX.shape)\n","# save arrays to one file in compressed format\n","savez_compressed('kelas-embeddings.npz', newTrainX, trainy, newTestX, testy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jNV1nOdrssv3","executionInfo":{"status":"ok","timestamp":1652718749433,"user_tz":-420,"elapsed":18181,"user":{"displayName":"33221018 Arief Sartono","userId":"11452593645263556956"}},"outputId":"d922b41b-49a6-4749-85d0-03b5ac64553d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded:  (79, 160, 160, 3) (79,) (27, 160, 160, 3) (27,)\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","Loaded Model\n","(79, 128)\n","(27, 128)\n"]}]},{"cell_type":"markdown","source":["Step 5 - Develop Classifier"],"metadata":{"id":"0bGmDVNpsyDY"}},{"cell_type":"code","source":["# develop a classifier for the Dataset\n","from random import choice\n","from numpy import load\n","from numpy import expand_dims\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import Normalizer\n","from sklearn.svm import SVC\n","from matplotlib import pyplot\n","# load faces\n","data = load('kelas-dataset.npz')\n","testX_faces = data['arr_2']\n","# load face embeddings\n","data = load('kelas-embeddings.npz')\n","trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n","# normalize input vectors\n","in_encoder = Normalizer(norm='l2')\n","trainX = in_encoder.transform(trainX)\n","testX = in_encoder.transform(testX)\n","# label encode targets\n","out_encoder = LabelEncoder()\n","out_encoder.fit(trainy)\n","trainy = out_encoder.transform(trainy)\n","testy = out_encoder.transform(testy)\n","# fit model\n","model = SVC(kernel='linear', probability=True)\n","model.fit(trainX, trainy)\n","# test model on a random example from the test dataset\n","#selection = choice([i for i in range(testX.shape[0])])\n","\n","#select picture to test\n","for selection in range (testX.shape[0]) :\n","  random_face_pixels = testX_faces[selection]\n","  random_face_emb = testX[selection]\n","  random_face_class = testy[selection]\n","  random_face_name = out_encoder.inverse_transform([random_face_class])\n","  # prediction for the face\n","  samples = expand_dims(random_face_emb, axis=0)\n","  yhat_class = model.predict(samples)\n","  yhat_prob = model.predict_proba(samples)\n","  # get name\n","  class_index = yhat_class[0]\n","  class_probability = yhat_prob[0,class_index] * 100\n","  predict_names = out_encoder.inverse_transform(yhat_class)\n","  print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n","  print('Expected: %s' % random_face_name[0])\n","  # plot for fun\n","  pyplot.imshow(random_face_pixels)\n","  title = '%s (%.3f)' % (predict_names[0], class_probability)\n","  pyplot.title(title)\n","  pyplot.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1LAO9TyRe7SA5TQR5jmaV4175xQOJ6EXF"},"id":"rbosF3Uesy3d","executionInfo":{"status":"ok","timestamp":1652718766638,"user_tz":-420,"elapsed":7565,"user":{"displayName":"33221018 Arief Sartono","userId":"11452593645263556956"}},"outputId":"a60f6191-5153-49f5-ad4d-d49aab6b07e2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}